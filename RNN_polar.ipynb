{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bus_v', 'cur', 'bus_freq', 'mac_ang', 'mac_spd', 'pelect', 'pmech', 'qelect', 'length', 'filename')\n",
      "(1, 5277)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/jiamingli/transient\" target=\"_blank\">https://app.wandb.ai/jiamingli/transient</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/jiamingli/transient/runs/1x58d04r\" target=\"_blank\">https://app.wandb.ai/jiamingli/transient/runs/1x58d04r</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "matfile = sio.loadmat('data_mac1_cleaned.mat')\n",
    "data = matfile['data']\n",
    "\n",
    "print(data.dtype.names)\n",
    "print(data.shape)\n",
    "# format: data['variable name'] [0] [sample index] [0] [time step]\n",
    "# e.g.: print(data['bus_v']     [0]     [432]      [0]   [124])\n",
    "\n",
    "use_wandb = True\n",
    "if use_wandb:\n",
    "    import wandb, os\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = 'RNN_polar.ipynb'\n",
    "    wandb.init(project=\"transient\", notes=\"\")\n",
    "    wandb.run.name = 'LSTM_CLinIter_2_400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event1836a5a39.mat'] skipped [1867.59786966]\n",
      "['event1986a5a69.mat'] skipped [1867.59786969]\n",
      "['event1994a5a70.mat'] skipped [1867.59810327]\n",
      "['event1948a5a61.mat'] skipped [1867.59996744]\n",
      "['event1809a5a33.mat'] skipped [1867.59810323]\n",
      "['event1979a5a67.mat'] skipped [1867.59810322]\n",
      "['event1977a5a67.mat'] skipped [1867.59843031]\n",
      "['event1758a5a23.mat'] skipped [1867.59996739]\n",
      "['event1671a5a6.mat'] skipped [1867.59786959]\n",
      "['event2018a5a75.mat'] skipped [1867.59996745]\n",
      "['event1839a5a39.mat'] skipped [1867.59810324]\n",
      "['event1872a5a46.mat'] skipped [1867.59843036]\n",
      "['event1980a5a67.mat'] skipped [1867.5972623]\n",
      "['event1989a5a69.mat'] skipped [1867.59810326]\n",
      "['event2001a5a72.mat'] skipped [1867.59786968]\n",
      "['event1999a5a71.mat'] skipped [1867.59810327]\n",
      "['event1840a5a39.mat'] skipped [1867.59726232]\n",
      "['event1850a5a41.mat'] skipped [1867.59726237]\n",
      "['event1993a5a70.mat'] skipped [1867.59996745]\n",
      "['event1675a5a6.mat'] skipped [1867.59726224]\n",
      "['event1674a5a6.mat'] skipped [1867.59810318]\n",
      "['event1988a5a69.mat'] skipped [1867.59996744]\n",
      "['event1949a5a61.mat'] skipped [1867.59810326]\n",
      "['event1826a5a37.mat'] skipped [1867.59786966]\n",
      "['event1683a5a8.mat'] skipped [1867.59996737]\n",
      "['event1961a5a64.mat'] skipped [1867.59786967]\n",
      "Train data set size: (700, 1600, 9)\n",
      "Test data set size: (700, 400, 9)\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "np.random.seed(20200412)\n",
    "n_sample = 1600\n",
    "data_len = 700\n",
    "use_mac_ang_filter = True\n",
    "use_Polar = True\n",
    "use_cur_sum = True\n",
    "if use_wandb:\n",
    "    wandb.config.training_sample = n_sample\n",
    "    wandb.config.data_len = data_len\n",
    "    wandb.config.use_mac_ang_filter = use_mac_ang_filter\n",
    "    wandb.config.use_Polar = use_Polar\n",
    "    wandb.config.use_cur_sum = use_cur_sum\n",
    "\n",
    "sample_idx = np.random.permutation(5277)\n",
    "\n",
    "### load training data ###\n",
    "if use_cur_sum:\n",
    "    train_data = np.zeros((data_len, n_sample, 9), dtype=np.float64)\n",
    "else:\n",
    "    train_data = np.zeros((data_len, n_sample, 18), dtype=np.float64)\n",
    "train_label_raw = np.zeros((data_len, n_sample, 7), dtype=np.float64)\n",
    "n_entry = 0\n",
    "for i in sample_idx[:4500]:\n",
    "    bus_v = data['bus_v'][0][i].reshape(-1, 1)\n",
    "    cur = data['cur'][0][i].reshape(-1, 1)\n",
    "#     bus_freq = data['bus_freq'][0][i].reshape(-1, 1)\n",
    "    mac_ang = data['mac_ang'][0][i].reshape(-1, 1)\n",
    "    mac_spd = data['mac_spd'][0][i].reshape(-1, 1)\n",
    "    pelect = data['pelect'][0][i].reshape(-1, 1)\n",
    "    pmech = data['pmech'][0][i].reshape(-1, 1)\n",
    "    qelect = data['qelect'][0][i].reshape(-1, 1)\n",
    "    length = qelect.shape[0]\n",
    "    \n",
    "    if use_mac_ang_filter and mac_ang[-1]>1000:\n",
    "        print(data['filename'][0][i], 'skipped', mac_ang[-1])\n",
    "        continue\n",
    "\n",
    "#     if use_cur_sum:\n",
    "#         cur = np.sum(cur, axis=1).reshape(-1, 1)\n",
    "\n",
    "    bus_v_ang = np.unwrap(np.angle(bus_v).reshape(-1)).reshape(-1,1)\n",
    "    cur_ang = np.unwrap(np.angle(cur).reshape(-1)).reshape(-1,1)\n",
    "#     tmp_train_data = np.hstack([np.abs(bus_v), bus_v_ang, np.abs(cur), cur_ang, bus_freq, mac_ang, mac_spd, pelect, pmech, qelect])\n",
    "    tmp_train_data = np.hstack([np.abs(bus_v), bus_v_ang, np.abs(cur), cur_ang, mac_ang, mac_spd, pelect, pmech, qelect])\n",
    "    tmp_train_data = tmp_train_data[:data_len+1, :]\n",
    "    \n",
    "    tmp_train_label = np.delete(tmp_train_data, 0, 0)  # delete the first sample(shift the curve left)\n",
    "\n",
    "    # delete the currents(we don't need to predict that)\n",
    "    if use_cur_sum:\n",
    "        tmp_train_label = np.delete(tmp_train_label, np.arange(2, 4), 1)\n",
    "    else:\n",
    "        tmp_train_label = np.delete(tmp_train_label, np.arange(2, 12), 1)\n",
    "    tmp_train_data = np.delete(tmp_train_data, -1, 0)  # delete the last sample because there's no corresponding label\n",
    "\n",
    "    length = tmp_train_data.shape[0]\n",
    "    train_data[:, n_entry, :] = tmp_train_data\n",
    "    train_label_raw[:, n_entry, :] = tmp_train_label\n",
    "    n_entry += 1\n",
    "    if n_entry >= n_sample:\n",
    "        break\n",
    "train_data = train_data[:, :n_entry, :]\n",
    "train_label_raw = train_label_raw[:, :n_entry, :]\n",
    "del tmp_train_data\n",
    "del tmp_train_label\n",
    "\n",
    "### load testing data ###\n",
    "if use_cur_sum:\n",
    "    test_data = np.zeros((data_len, 400, 9), dtype=np.float64)\n",
    "else:\n",
    "    test_data = np.zeros((data_len, 400, 18), dtype=np.float64)\n",
    "test_label_raw = np.zeros((data_len, 400, 7), dtype=np.float64)\n",
    "\n",
    "n_entry = 0\n",
    "for i in sample_idx[4800:]:\n",
    "    bus_v = data['bus_v'][0][i].reshape(-1, 1)\n",
    "    cur = data['cur'][0][i].reshape(-1, 1)\n",
    "#     bus_freq = data['bus_freq'][0][i].reshape(-1, 1)\n",
    "    mac_ang = data['mac_ang'][0][i].reshape(-1, 1)\n",
    "    mac_spd = data['mac_spd'][0][i].reshape(-1, 1)\n",
    "    pelect = data['pelect'][0][i].reshape(-1, 1)\n",
    "    pmech = data['pmech'][0][i].reshape(-1, 1)\n",
    "    qelect = data['qelect'][0][i].reshape(-1, 1)\n",
    "    length = qelect.shape[0]\n",
    "\n",
    "    if use_mac_ang_filter and mac_ang[-1]>1000:\n",
    "        print(data['filename'][0][i], 'skipped', mac_ang[-1])\n",
    "        continue\n",
    "\n",
    "#     if use_cur_sum:\n",
    "#         cur = np.sum(cur, axis=1).reshape(-1, 1)\n",
    "\n",
    "    bus_v_ang = np.unwrap(np.angle(bus_v).reshape(-1)).reshape(-1,1)\n",
    "    cur_ang = np.unwrap(np.angle(cur).reshape(-1)).reshape(-1,1)\n",
    "#     tmp_test_data = np.hstack([np.abs(bus_v), bus_v_ang, np.abs(cur), cur_ang, bus_freq, mac_ang, mac_spd, pelect, pmech, qelect])\n",
    "    tmp_test_data = np.hstack([np.abs(bus_v), bus_v_ang, np.abs(cur), cur_ang, mac_ang, mac_spd, pelect, pmech, qelect])\n",
    "    tmp_test_data = tmp_test_data[:data_len+1, :]\n",
    "    \n",
    "    tmp_test_label = np.delete(tmp_test_data, 0, 0)  # delete the first sample(shift the curve left)\n",
    "    if use_cur_sum:\n",
    "        tmp_test_label = np.delete(tmp_test_label, np.arange(2, 4), 1)\n",
    "    else:\n",
    "        tmp_test_label = np.delete(tmp_test_label, np.arange(2, 12), 1)\n",
    "    tmp_test_data = np.delete(tmp_test_data, -1, 0)  # delete the last sample because there's no corresponding label\n",
    "    length = tmp_test_data.shape[0]\n",
    "    test_data[:, n_entry, :] = tmp_test_data\n",
    "    test_label_raw[:, n_entry, :] = tmp_test_label\n",
    "    n_entry += 1\n",
    "    if n_entry >= 400:\n",
    "        break\n",
    "    \n",
    "test_data = test_data[:, :n_entry, :]\n",
    "test_label_raw = test_label_raw[:, :n_entry, :]\n",
    "del tmp_test_data\n",
    "del tmp_test_label\n",
    "\n",
    "# train_label_raw[:, :2] = train_data[:, :2]\n",
    "# test_label_raw[:, :2] = test_data[:, :2]\n",
    "\n",
    "# compute difference\n",
    "# if use_cur_sum:\n",
    "#     train_label = train_label_raw# - train_data[:, [0, 1, 4, 5, 6, 7, 8, 9]]\n",
    "#     test_label = test_label_raw# - test_data[:, [0, 1, 4, 5, 6, 7, 8, 9]]\n",
    "# else:\n",
    "#     train_label = train_label_raw# - train_data[:, [0, 1, 12, 13, 14, 15, 16, 17]]\n",
    "#     test_label = test_label_raw# - test_data[:, [0, 1, 12, 13, 14, 15, 16, 17]]\n",
    "train_label = train_label_raw.copy()\n",
    "test_label = test_label_raw.copy()\n",
    "\n",
    "# clip angle to [-pi, pi]\n",
    "# train_label[:, 1] = np.mod(train_label[:, 1]+np.pi, 2*np.pi) - np.pi\n",
    "# test_label[:, 1] = np.mod(test_label[:, 1]+np.pi, 2*np.pi) - np.pi\n",
    "\n",
    "# train_label[:, :3] = 0\n",
    "# test_label[:, :3] = 0\n",
    "\n",
    "# # normalize testing data\n",
    "label_mean = np.mean(train_label.reshape(n_sample*data_len,-1), axis=0)\n",
    "label_std = np.std(train_label.reshape(n_sample*data_len,-1), axis=0)\n",
    "label_std[np.less(label_std, 1e-7)] = 1e-7\n",
    "# label_mean[1] = 0  # remove normalization on angle of bus_v\n",
    "# label_std[1] = 1\n",
    "train_label = (train_label - label_mean) / label_std\n",
    "test_label = (test_label - label_mean) / label_std\n",
    "\n",
    "# # normalize training data\n",
    "data_mean = np.mean(train_data.reshape(n_sample*data_len,-1), axis=0)\n",
    "data_std = np.std(train_data.reshape(n_sample*data_len,-1), axis=0)\n",
    "data_std[np.less(data_std, 1e-7)] = 1e-7\n",
    "train_data = (train_data - data_mean) / data_std\n",
    "test_data = (test_data - data_mean) / data_std\n",
    "\n",
    "print('Train data set size:', train_data.shape)\n",
    "print('Test data set size:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Will be applied.\n",
      "The model has 1,943,607 trainable parameters\n",
      "Before training: train Loss = 8.528e-01, test Loss = 8.551e-01\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class RNNNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RNNNetwork, self).__init__()\n",
    "        self.hidden_dim = 400\n",
    "        self.n_layers = 2\n",
    "        \n",
    "        if use_wandb:\n",
    "            wandb.config.architecture = 'LSTM'\n",
    "            wandb.config.n_layers = self.n_layers\n",
    "            wandb.config.hidden_dim = self.hidden_dim\n",
    "\n",
    "#         self.initial_hidden = torch.zeros(self.n_layers, 1, self.hidden_dim).to(device)\n",
    "#         self.initial_cell = torch.zeros(self.n_layers, 1, self.hidden_dim).to(device)\n",
    "#         self.initial_state = (self.initial_hidden, self.initial_cell)\n",
    "\n",
    "#         self.initial_cell = torch.zeros(self.n_layers, 1, self.hidden_dim).to(device)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=9, hidden_size=self.hidden_dim, num_layers=self.n_layers)\n",
    "#         self.gru = nn.GRU(input_size=10, hidden_size=self.hidden_dim, num_layers=self.n_layers)\n",
    "\n",
    "        self.outputlayer = nn.Linear(self.hidden_dim, 7)\n",
    "\n",
    "    def forward(self, x, states=None):\n",
    "        data_len = x.size()[0]\n",
    "        data_batch = x.size()[1]\n",
    "\n",
    "        # LSTM\n",
    "        (hidden_state, cell_state) = (None, None) if states is None else states\n",
    "        if hidden_state is None:\n",
    "            hidden_state = torch.zeros(self.n_layers, data_batch, self.hidden_dim).to(device)\n",
    "        if cell_state is None:\n",
    "            cell_state = torch.zeros(self.n_layers, data_batch, self.hidden_dim).to(device)\n",
    "\n",
    "        rnn_out, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n",
    "        states = (hidden_state, cell_state)\n",
    "\n",
    "        # GRU\n",
    "#         if states is None:\n",
    "#             states = torch.zeros(self.n_layers, data_batch, self.hidden_dim).to(device)\n",
    "#         rnn_out, states = self.gru(x, states)\n",
    "\n",
    "        pred = self.outputlayer(rnn_out.view(-1, self.hidden_dim))\n",
    "        return pred.view(data_len, data_batch, 7), states\n",
    "\n",
    "    def initial_states(self):\n",
    "        return None\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        #         torch.nn.init.kaiming_normal_(m.weight)\n",
    "        #         torch.nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "        torch.nn.init.normal_(m.bias, mean=0, std=0.001)\n",
    "        nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "#         nn.init.kaiming_uniform_(m.bias, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    if isinstance(m, nn.BatchNorm1d):\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        torch.nn.init.ones_(m.weight)\n",
    "\n",
    "\n",
    "torch.manual_seed(20200410)\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU is available. Will be applied.')\n",
    "    use_GPU = True\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.manual_seed(20200410)\n",
    "    torch.cuda.manual_seed_all(20200410)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "    use_GPU = False\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = RNNNetwork().float()\n",
    "model.apply(weights_init)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "\n",
    "batchsize = 200\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01*2, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "train_data_torch = torch.from_numpy(train_data).float()\n",
    "train_label_torch = torch.from_numpy(train_label).float()\n",
    "test_data_torch = torch.from_numpy(test_data).float()\n",
    "test_label_torch = torch.from_numpy(test_label).float()\n",
    "\n",
    "\n",
    "def test(data_torch, label_torch):\n",
    "    loss = None\n",
    "    prediction = None\n",
    "    model.eval()\n",
    "    test_batchsize = 400\n",
    "    with torch.no_grad():\n",
    "        for j in range(0, data_torch.shape[1], test_batchsize):\n",
    "            inputs_torch = data_torch[:, j:j+test_batchsize, :]\n",
    "            labels_torch = label_torch[:, j:j+test_batchsize, :]\n",
    "\n",
    "            inputs_torch = inputs_torch.to(device)\n",
    "            labels_torch = labels_torch.to(device)\n",
    "\n",
    "            # forward\n",
    "            pred_torch, _ = model(inputs_torch)\n",
    "            loss_torch = criterion(pred_torch, labels_torch)\n",
    "\n",
    "            if use_GPU:\n",
    "                pred_torch = pred_torch.cpu()\n",
    "            pred = pred_torch.data.numpy()\n",
    "\n",
    "            loss = np.array([loss_torch.item()]) if loss is None else np.hstack([loss, loss_torch.item()])\n",
    "            prediction = pred if prediction is None else np.concatenate([prediction, pred], axis=1)\n",
    "    return loss.mean(), prediction\n",
    "\n",
    "def evaluation(eval_data_torch, eval_label_raw):\n",
    "    t_max = 699\n",
    "    samples = eval_data_torch.shape[1]\n",
    "    eval_batchsize = 400\n",
    "    rse = np.zeros((samples,7))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,samples,eval_batchsize):\n",
    "            rnn_states = model.initial_states()\n",
    "            output_data = np.zeros((t_max, eval_batchsize, 7))\n",
    "            input_data_torch = eval_data_torch[0, i:i+eval_batchsize, :].reshape(1,eval_batchsize,-1).to(device)\n",
    "\n",
    "            for t in range(0, t_max):\n",
    "                output_data_torch, rnn_states = model(input_data_torch, rnn_states)\n",
    "                output_data[t,:] = output_data_torch.data.cpu().numpy()\n",
    "                input_data_torch = torch.cat((output_data_torch[0,:,0:2], eval_data_torch[t+1,i:i+eval_batchsize,2:4].to(device), output_data_torch[0,:,2:7], eval_data_torch[t+1,i:i+eval_batchsize,9:11].to(device)), dim=1).reshape(1,eval_batchsize,-1)\n",
    "\n",
    "            output_data = output_data * label_std + label_mean\n",
    "\n",
    "            for b in range(eval_batchsize):\n",
    "                for q in range(7):\n",
    "                    if q == 5:\n",
    "                        # skip pmech, which is a constant\n",
    "                        continue\n",
    "                    truth_curve = eval_label_raw[:t_max, i+b, q]\n",
    "                    pred_curve = output_data[:t_max, b, q]\n",
    "                    rse[i+b,q] = np.linalg.norm(truth_curve - pred_curve, 2)/ (np.linalg.norm(truth_curve-truth_curve.mean(), 2) + 1e-6)\n",
    "    return rse\n",
    "\n",
    "loss, _ = test(train_data_torch, train_label_torch)\n",
    "loss_test, _ = test(test_data_torch, test_label_torch)\n",
    "print('Before training: train Loss = %.3e, test Loss = %.3e' % (loss, loss_test))\n",
    "\n",
    "\n",
    "checkpoint = torch.load('saved_models/g2ye3u17/900.pt')\n",
    "# checkpoint = torch.load('wandb/run-20200526_171526-38rgv01w/model.pt')\n",
    "if 'checkpoint' in locals():\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "trained_epochs = 1\n",
    "loss_curve = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:19:18  ETA:402.9mins Epoch 910: train Loss = 1.866e-03, test Loss = 6.504e-03, eval = 1.482e-01\n",
      "11:21:15  ETA:392.7mins Epoch 920: train Loss = 1.855e-03, test Loss = 7.396e-03, eval = 1.383e-01\n",
      "11:23:14  ETA:391.2mins Epoch 930: train Loss = 1.600e-03, test Loss = 7.845e-03, eval = 1.245e-01\n",
      "11:25:13  ETA:388.8mins Epoch 940: train Loss = 1.270e-03, test Loss = 6.648e-03, eval = 1.338e-01\n",
      "11:27:11  ETA:386.5mins Epoch 950: train Loss = 7.252e-04, test Loss = 6.324e-03, eval = 1.146e-01\n",
      "11:29:09  ETA:384.2mins Epoch 960: train Loss = 7.450e-04, test Loss = 5.461e-03, eval = 1.154e-01\n",
      "11:31:09  ETA:382.4mins Epoch 970: train Loss = 7.681e-04, test Loss = 5.925e-03, eval = 1.164e-01\n",
      "11:33:08  ETA:380.6mins Epoch 980: train Loss = 1.598e-03, test Loss = 6.412e-03, eval = 1.243e-01\n",
      "11:35:06  ETA:378.4mins Epoch 990: train Loss = 1.632e-03, test Loss = 7.089e-03, eval = 1.264e-01\n",
      "11:37:06  ETA:376.9mins Epoch 1000: train Loss = 1.059e-03, test Loss = 6.072e-03, eval = 1.114e-01\n",
      "11:39:07  ETA:375.4mins Epoch 1010: train Loss = 1.274e-03, test Loss = 6.791e-03, eval = 1.187e-01\n",
      "11:41:06  ETA:373.3mins Epoch 1020: train Loss = 1.041e-03, test Loss = 6.296e-03, eval = 1.117e-01\n",
      "11:43:06  ETA:371.6mins Epoch 1030: train Loss = 1.609e-03, test Loss = 6.316e-03, eval = 1.161e-01\n",
      "11:45:07  ETA:370.0mins Epoch 1040: train Loss = 1.644e-03, test Loss = 6.841e-03, eval = 1.269e-01\n",
      "11:47:08  ETA:368.4mins Epoch 1050: train Loss = 8.826e-04, test Loss = 6.620e-03, eval = 1.077e-01\n",
      "11:49:04  ETA:365.7mins Epoch 1060: train Loss = 9.594e-04, test Loss = 7.424e-03, eval = 1.195e-01\n",
      "11:51:01  ETA:363.4mins Epoch 1070: train Loss = 6.926e-04, test Loss = 6.878e-03, eval = 1.138e-01\n",
      "11:53:01  ETA:361.5mins Epoch 1080: train Loss = 1.507e-03, test Loss = 8.006e-03, eval = 1.248e-01\n",
      "11:55:03  ETA:359.9mins Epoch 1090: train Loss = 9.698e-04, test Loss = 6.823e-03, eval = 1.194e-01\n",
      "11:57:03  ETA:358.2mins Epoch 1100: train Loss = 1.361e-03, test Loss = 7.851e-03, eval = 1.196e-01\n",
      "11:59:02  ETA:356.1mins Epoch 1110: train Loss = 1.924e-03, test Loss = 7.506e-03, eval = 1.308e-01\n",
      "12:01:00  ETA:353.9mins Epoch 1120: train Loss = 1.158e-03, test Loss = 7.254e-03, eval = 1.125e-01\n",
      "12:02:59  ETA:351.9mins Epoch 1130: train Loss = 3.284e-03, test Loss = 9.554e-03, eval = 1.595e-01\n",
      "12:04:59  ETA:350.0mins Epoch 1140: train Loss = 1.288e-03, test Loss = 9.174e-03, eval = 1.113e-01\n",
      "12:06:57  ETA:347.9mins Epoch 1150: train Loss = 1.602e-03, test Loss = 1.070e-02, eval = 1.138e-01\n",
      "12:08:59  ETA:346.2mins Epoch 1160: train Loss = 2.447e-03, test Loss = 1.297e-02, eval = 1.188e-01\n",
      "12:10:59  ETA:344.3mins Epoch 1170: train Loss = 9.539e-04, test Loss = 1.650e-02, eval = 1.070e-01\n",
      "12:13:01  ETA:342.6mins Epoch 1180: train Loss = 1.122e-03, test Loss = 1.141e-02, eval = 9.963e-02\n",
      "12:15:03  ETA:340.9mins Epoch 1190: train Loss = 2.891e-03, test Loss = 1.943e-02, eval = 1.250e-01\n",
      "12:17:04  ETA:339.0mins Epoch 1200: train Loss = 1.696e-03, test Loss = 1.691e-02, eval = 1.143e-01\n",
      "12:19:05  ETA:337.1mins Epoch 1210: train Loss = 2.156e-03, test Loss = 2.096e-02, eval = 1.118e-01\n",
      "12:21:04  ETA:335.1mins Epoch 1220: train Loss = 1.327e-03, test Loss = 9.102e-03, eval = 1.009e-01\n",
      "12:23:05  ETA:333.2mins Epoch 1230: train Loss = 2.251e-03, test Loss = 9.884e-03, eval = 1.001e-01\n",
      "12:25:05  ETA:331.3mins Epoch 1240: train Loss = 1.682e-03, test Loss = 1.186e-02, eval = 1.080e-01\n",
      "12:27:07  ETA:329.4mins Epoch 1250: train Loss = 2.213e-03, test Loss = 1.034e-02, eval = 1.110e-01\n",
      "12:29:08  ETA:327.5mins Epoch 1260: train Loss = 1.774e-03, test Loss = 1.498e-02, eval = 1.106e-01\n",
      "12:31:07  ETA:325.4mins Epoch 1270: train Loss = 3.768e-03, test Loss = 1.851e-02, eval = 1.334e-01\n",
      "12:33:09  ETA:323.6mins Epoch 1280: train Loss = 1.527e-03, test Loss = 1.157e-02, eval = 1.076e-01\n",
      "12:35:10  ETA:321.7mins Epoch 1290: train Loss = 1.992e-03, test Loss = 8.180e-03, eval = 1.127e-01\n",
      "12:37:12  ETA:319.9mins Epoch 1300: train Loss = 2.340e-03, test Loss = 1.324e-02, eval = 1.026e-01\n",
      "12:39:13  ETA:318.0mins Epoch 1310: train Loss = 1.800e-03, test Loss = 1.285e-02, eval = 9.952e-02\n",
      "12:41:15  ETA:316.1mins Epoch 1320: train Loss = 1.469e-03, test Loss = 1.178e-02, eval = 9.733e-02\n",
      "12:43:17  ETA:314.2mins Epoch 1330: train Loss = 5.125e-03, test Loss = 1.388e-02, eval = 1.408e-01\n",
      "12:45:16  ETA:312.1mins Epoch 1340: train Loss = 2.752e-03, test Loss = 2.186e-02, eval = 1.109e-01\n",
      "12:47:18  ETA:310.3mins Epoch 1350: train Loss = 1.218e-03, test Loss = 1.831e-02, eval = 1.059e-01\n",
      "12:49:19  ETA:308.3mins Epoch 1360: train Loss = 2.937e-03, test Loss = 2.183e-02, eval = 1.045e-01\n",
      "12:51:20  ETA:306.4mins Epoch 1370: train Loss = 2.477e-03, test Loss = 2.275e-02, eval = 9.396e-02\n",
      "12:53:21  ETA:304.4mins Epoch 1380: train Loss = 3.123e-03, test Loss = 1.843e-02, eval = 9.936e-02\n",
      "12:55:21  ETA:302.4mins Epoch 1390: train Loss = 2.559e-03, test Loss = 1.879e-02, eval = 1.041e-01\n",
      "12:57:21  ETA:300.4mins Epoch 1400: train Loss = 3.566e-03, test Loss = 2.455e-02, eval = 1.194e-01\n",
      "12:59:21  ETA:298.4mins Epoch 1410: train Loss = 2.155e-03, test Loss = 2.350e-02, eval = 1.009e-01\n",
      "13:01:22  ETA:296.5mins Epoch 1420: train Loss = 5.338e-03, test Loss = 2.590e-02, eval = 1.117e-01\n",
      "13:03:24  ETA:294.5mins Epoch 1430: train Loss = 6.777e-03, test Loss = 2.317e-02, eval = 1.292e-01\n",
      "13:05:26  ETA:292.6mins Epoch 1440: train Loss = 5.955e-03, test Loss = 2.690e-02, eval = 1.181e-01\n",
      "13:07:27  ETA:290.7mins Epoch 1450: train Loss = 4.548e-03, test Loss = 2.577e-02, eval = 1.140e-01\n",
      "13:09:28  ETA:288.7mins Epoch 1460: train Loss = 1.533e-02, test Loss = 3.648e-02, eval = 1.486e-01\n",
      "13:11:28  ETA:286.7mins Epoch 1470: train Loss = 2.219e-03, test Loss = 2.198e-02, eval = 9.814e-02\n",
      "13:13:31  ETA:284.8mins Epoch 1480: train Loss = 2.020e-03, test Loss = 2.281e-02, eval = 9.677e-02\n",
      "13:15:33  ETA:282.8mins Epoch 1490: train Loss = 1.969e-03, test Loss = 2.253e-02, eval = 9.327e-02\n",
      "13:17:34  ETA:280.9mins Epoch 1500: train Loss = 4.062e-03, test Loss = 1.940e-02, eval = 1.056e-01\n",
      "13:19:36  ETA:278.9mins Epoch 1510: train Loss = 3.019e-03, test Loss = 2.274e-02, eval = 1.065e-01\n",
      "13:21:37  ETA:277.0mins Epoch 1520: train Loss = 3.594e-02, test Loss = 5.872e-02, eval = 1.534e-01\n",
      "13:23:40  ETA:275.0mins Epoch 1530: train Loss = 2.139e-02, test Loss = 4.077e-02, eval = 1.442e-01\n",
      "13:25:41  ETA:273.0mins Epoch 1540: train Loss = 8.769e-03, test Loss = 2.444e-02, eval = 9.905e-02\n",
      "13:27:42  ETA:271.1mins Epoch 1550: train Loss = 3.295e-03, test Loss = 1.378e-02, eval = 1.009e-01\n",
      "13:29:44  ETA:269.1mins Epoch 1560: train Loss = 9.246e-03, test Loss = 2.817e-02, eval = 1.076e-01\n",
      "13:31:47  ETA:267.2mins Epoch 1570: train Loss = 8.024e-03, test Loss = 2.465e-02, eval = 9.880e-02\n",
      "13:33:49  ETA:265.3mins Epoch 1580: train Loss = 3.515e-02, test Loss = 4.653e-02, eval = 1.252e-01\n",
      "13:35:52  ETA:263.3mins Epoch 1590: train Loss = 2.271e-01, test Loss = 2.490e-01, eval = 2.352e-01\n",
      "13:37:54  ETA:261.3mins Epoch 1600: train Loss = 1.517e-01, test Loss = 2.080e-01, eval = 1.683e-01\n",
      "13:39:56  ETA:259.4mins Epoch 1610: train Loss = 4.224e-02, test Loss = 6.460e-02, eval = 1.465e-01\n",
      "13:41:57  ETA:257.4mins Epoch 1620: train Loss = 1.562e-01, test Loss = 1.911e-01, eval = 1.430e-01\n",
      "13:43:59  ETA:255.4mins Epoch 1630: train Loss = 3.076e-02, test Loss = 4.483e-02, eval = 1.120e-01\n",
      "13:46:01  ETA:253.5mins Epoch 1640: train Loss = 3.373e-02, test Loss = 5.797e-02, eval = 1.153e-01\n",
      "13:48:03  ETA:251.5mins Epoch 1650: train Loss = 3.798e-01, test Loss = 3.922e-01, eval = 1.531e-01\n",
      "13:50:05  ETA:249.5mins Epoch 1660: train Loss = 2.144e-01, test Loss = 2.328e-01, eval = 2.236e-01\n",
      "13:52:07  ETA:247.5mins Epoch 1670: train Loss = 5.502e-02, test Loss = 7.089e-02, eval = 1.704e-01\n",
      "13:54:09  ETA:245.6mins Epoch 1680: train Loss = 4.284e-02, test Loss = 5.240e-02, eval = 1.293e-01\n",
      "13:56:10  ETA:243.6mins Epoch 1690: train Loss = 2.123e-02, test Loss = 6.182e-02, eval = 1.156e-01\n",
      "13:58:11  ETA:241.6mins Epoch 1700: train Loss = 5.240e-02, test Loss = 6.641e-02, eval = 1.192e-01\n",
      "14:00:14  ETA:239.6mins Epoch 1710: train Loss = 9.166e-02, test Loss = 1.350e-01, eval = 1.372e-01\n",
      "14:02:16  ETA:237.6mins Epoch 1720: train Loss = 6.639e-02, test Loss = 7.834e-02, eval = 1.118e-01\n",
      "14:04:17  ETA:235.6mins Epoch 1730: train Loss = 4.440e-02, test Loss = 7.536e-02, eval = 1.130e-01\n",
      "14:06:19  ETA:233.6mins Epoch 1740: train Loss = 1.531e-01, test Loss = 1.619e-01, eval = 4.445e-01\n",
      "14:08:20  ETA:231.6mins Epoch 1750: train Loss = 6.597e-01, test Loss = 6.782e-01, eval = 2.635e-01\n",
      "14:10:23  ETA:229.7mins Epoch 1760: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:12:25  ETA:227.7mins Epoch 1770: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:14:26  ETA:225.7mins Epoch 1780: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:16:27  ETA:223.7mins Epoch 1790: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:18:29  ETA:221.7mins Epoch 1800: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:20:30  ETA:219.7mins Epoch 1810: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:22:32  ETA:217.7mins Epoch 1820: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:24:34  ETA:215.7mins Epoch 1830: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:26:35  ETA:213.7mins Epoch 1840: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:28:37  ETA:211.7mins Epoch 1850: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:30:38  ETA:209.7mins Epoch 1860: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:32:39  ETA:207.7mins Epoch 1870: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:34:41  ETA:205.7mins Epoch 1880: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:36:42  ETA:203.7mins Epoch 1890: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:38:44  ETA:201.7mins Epoch 1900: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:40:46  ETA:199.7mins Epoch 1910: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:42:47  ETA:197.7mins Epoch 1920: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:44:49  ETA:195.6mins Epoch 1930: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:46:50  ETA:193.6mins Epoch 1940: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:48:52  ETA:191.6mins Epoch 1950: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:50:54  ETA:189.6mins Epoch 1960: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:52:56  ETA:187.6mins Epoch 1970: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:54:58  ETA:185.6mins Epoch 1980: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:57:00  ETA:183.6mins Epoch 1990: train Loss = nan, test Loss = nan, eval = nan\n",
      "14:59:02  ETA:181.6mins Epoch 2000: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:01:04  ETA:179.6mins Epoch 2010: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:03:05  ETA:177.6mins Epoch 2020: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:05:06  ETA:175.6mins Epoch 2030: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:07:08  ETA:173.6mins Epoch 2040: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:09:09  ETA:171.6mins Epoch 2050: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:11:11  ETA:169.6mins Epoch 2060: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:13:12  ETA:167.6mins Epoch 2070: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:15:14  ETA:165.6mins Epoch 2080: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:17:16  ETA:163.5mins Epoch 2090: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:19:18  ETA:161.5mins Epoch 2100: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:21:19  ETA:159.5mins Epoch 2110: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:23:20  ETA:157.5mins Epoch 2120: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:25:22  ETA:155.5mins Epoch 2130: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:27:24  ETA:153.5mins Epoch 2140: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:29:25  ETA:151.5mins Epoch 2150: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:31:27  ETA:149.5mins Epoch 2160: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:33:29  ETA:147.5mins Epoch 2170: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:35:31  ETA:145.5mins Epoch 2180: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:37:32  ETA:143.4mins Epoch 2190: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:39:34  ETA:141.4mins Epoch 2200: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:41:36  ETA:139.4mins Epoch 2210: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:43:37  ETA:137.4mins Epoch 2220: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:45:39  ETA:135.4mins Epoch 2230: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:47:41  ETA:133.4mins Epoch 2240: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:49:43  ETA:131.4mins Epoch 2250: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:51:44  ETA:129.4mins Epoch 2260: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:53:46  ETA:127.3mins Epoch 2270: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:55:48  ETA:125.3mins Epoch 2280: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:57:50  ETA:123.3mins Epoch 2290: train Loss = nan, test Loss = nan, eval = nan\n",
      "15:59:52  ETA:121.3mins Epoch 2300: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:01:54  ETA:119.3mins Epoch 2310: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:03:56  ETA:117.3mins Epoch 2320: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:05:57  ETA:115.3mins Epoch 2330: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:07:59  ETA:113.3mins Epoch 2340: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:10:01  ETA:111.2mins Epoch 2350: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:12:03  ETA:109.2mins Epoch 2360: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:14:05  ETA:107.2mins Epoch 2370: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:16:07  ETA:105.2mins Epoch 2380: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:18:08  ETA:103.2mins Epoch 2390: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:20:10  ETA:101.2mins Epoch 2400: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:22:12  ETA:99.1mins Epoch 2410: train Loss = nan, test Loss = nan, eval = nan\n",
      "16:24:13  ETA:97.1mins Epoch 2420: train Loss = nan, test Loss = nan, eval = nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7715533d34f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label_torch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.1.11/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-15132afb87d8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, states)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.1.11/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.1.11/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "start_time = time.time()\n",
    "teacher_forcing_ratio_decay = True\n",
    "teacher_forcing_ratio = 0.75\n",
    "train_for_epochs = 2000\n",
    "if use_wandb:\n",
    "    wandb.config.teacher_forcing = teacher_forcing_ratio\n",
    "    wandb.config.teacher_forcing_ratio_decay = teacher_forcing_ratio_decay\n",
    "\n",
    "if 'checkpoint' in locals():\n",
    "    # to compatible with random seed\n",
    "    for i in range(trained_epochs, trained_epochs+checkpoint['epoch']):\n",
    "        if teacher_forcing_ratio_decay:\n",
    "            teacher_forcing_ratio *= 0.9975 #  0.9966\n",
    "        for j in range(0, n_sample, batchsize):\n",
    "            use_teacher_forcing = np.random.random()<teacher_forcing_ratio\n",
    "    trained_epochs = trained_epochs+checkpoint['epoch']\n",
    "    loss_curve = checkpoint['loss_curve']\n",
    "\n",
    "    if use_wandb:\n",
    "        loss, _ = test(train_data_torch, train_label_torch)\n",
    "        loss_test, _ = test(test_data_torch, test_label_torch)\n",
    "        rse = evaluation(test_data_torch, test_label_raw)\n",
    "        wandb.log({\"Epoch\": i, \"Train Loss\": loss, \"Test Loss\": loss_test, 'Eval RSE':np.median(rse,axis=0).mean()})\n",
    "\n",
    "\n",
    "for i in range(trained_epochs, trained_epochs+train_for_epochs):    \n",
    "    model.train()\n",
    "    if teacher_forcing_ratio_decay:\n",
    "        teacher_forcing_ratio *= 0.9975 #  0.9966\n",
    "\n",
    "    for j in range(0, n_sample, batchsize):\n",
    "        loss_r = np.zeros((700))\n",
    "#         input_batch = train_data_torch[:data_len, j:j+batchsize, :].reshape(data_len,batchsize,-1).to(device)\n",
    "#         outputs = torch.zeros((data_len,batchsize,8), dtype=torch.float32, device=device)\n",
    "        rnn_states = model.initial_states()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        use_teacher_forcing = np.random.random()<teacher_forcing_ratio\n",
    "        if use_teacher_forcing:\n",
    "#             with total teacher forcing, 20x faster\n",
    "            inputs = train_data_torch[:data_len, j:j+batchsize, :].reshape(data_len,batchsize,-1).to(device)\n",
    "            outputs, rnn_states = model(inputs, rnn_states)\n",
    "            labels = train_label_torch[:, j:j+batchsize, :].to(device)\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            for t in range(data_len):\n",
    "                inputs = train_data_torch[t, j:j+batchsize, :].reshape(1,batchsize,-1).clone().to(device)\n",
    "                if t>0:\n",
    "                    # teacher forcing: replacing inputs with ground truth\n",
    "                    inputs[:,:,[0,1,4,5,6,7,8]] = outputs[0,:,:].detach()\n",
    "\n",
    "                # forward\n",
    "                outputs, rnn_states = model(inputs, rnn_states)\n",
    "\n",
    "                labels = train_label_torch[t, j:j+batchsize, :].reshape(1,batchsize,-1).to(device)\n",
    "                loss += criterion(outputs, labels)\n",
    "                loss_r[t] = criterion(outputs, labels).cpu().data.numpy()\n",
    "            loss /= data_len\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clip\n",
    "#         torch.nn.utils.clip_grad_value_(model.parameters(), 0.002)\n",
    "#         torch.nn.utils.clip_grad_value_(model.parameters(), 0.0005)\n",
    "#         torch.nn.utils.clip_grad_value_(model.parameters(), 0.0001)\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 0.00002)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        loss, _ = test(train_data_torch, train_label_torch)\n",
    "        loss_test, _ = test(test_data_torch, test_label_torch)\n",
    "#         rse = evaluation(train_data_torch, train_label_torch)\n",
    "\n",
    "        rse_train = evaluation(train_data_torch, train_label_raw)\n",
    "        rse_test = evaluation(test_data_torch, test_label_raw)\n",
    "#         rse = evaluation(test_data_torch, test_label_raw)\n",
    "\n",
    "        loss_curve.append([i, loss, loss_test])\n",
    "        if use_wandb:\n",
    "            wandb.log({\"Epoch\": i, \"Train Loss\": loss, \"Test Loss\": loss_test, 'Eval RSE in training':np.median(rse_train,axis=0).mean(), 'Eval RSE':np.median(rse_test,axis=0).mean()})\n",
    "\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        ETA = (time.time() - start_time) / (i - trained_epochs + 1) * (trained_epochs+train_for_epochs-i) / 60\n",
    "        print(time.strftime('%H:%M:%S  ', time.localtime(time.time())), end=\"\")\n",
    "        print('ETA:{:.1f}mins '.format(ETA), end=\"\")\n",
    "        print('Epoch {}: train Loss = {:.3e}, test Loss = {:.3e}, eval = {:.3e}'.format(i, loss, loss_test, np.median(rse_test,axis=0).mean()))\n",
    "        \n",
    "    if use_wandb and i % 100 == 0:\n",
    "        if not os.path.exists('saved_models/{:s}/'.format(wandb.run.id)):\n",
    "            os.makedirs('saved_models/{:s}/'.format(wandb.run.id))\n",
    "        torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'epoch': i, 'loss_curve':loss_curve}, 'saved_models/{:s}/{:d}.pt'.format(wandb.run.id, i))\n",
    "\n",
    "\n",
    "\n",
    "trained_epochs = trained_epochs+train_for_epochs\n",
    "print('Training process took {:.1f} mins.'.format((time.time()-start_time)/60))\n",
    "\n",
    "if len(loss_curve) > 0:\n",
    "    plt.figure(0, figsize=(15, 5))\n",
    "    plt.plot(np.array(loss_curve)[:, 0], np.array(loss_curve)[:, 1], 'r', label=\"Train\")\n",
    "    plt.plot(np.array(loss_curve)[:, 0], np.array(loss_curve)[:, 2], 'b', label=\"Test\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "print('GPU memory stats: Max Cached {:.0f} Mb, Max Reserved {:.0f} Mb, Max Allocated {:.0f} Mb'.format(\n",
    "    torch.cuda.max_memory_cached(0)/1024/1024, torch.cuda.max_memory_reserved(0)/1024/1024, torch.cuda.max_memory_allocated(0)/1024/1024))\n",
    "\n",
    "_, prediction_train_raw = test(train_data_torch, train_label_torch)\n",
    "_, prediction_test_raw = test(test_data_torch, test_label_torch)\n",
    "\n",
    "if use_cur_sum:\n",
    "    prediction_train = prediction_train_raw * label_std + label_mean\n",
    "    prediction_test = prediction_test_raw * label_std + label_mean\n",
    "else:\n",
    "    prediction_train = prediction_train_raw * label_std + label_mean\n",
    "    prediction_test = prediction_test_raw * label_std + label_mean\n",
    "    \n",
    "mse_train = np.mean(np.mean(np.square(prediction_train - train_label_raw), axis=1), axis=0)\n",
    "mse_test = np.mean(np.mean(np.square(prediction_test - test_label_raw), axis=1), axis=0)\n",
    "\n",
    "print('Denormalized: train Loss = %.3e, test Loss = %.3e' % (mse_train.mean(), mse_test.mean()))\n",
    "\n",
    "se_train = np.linalg.norm(prediction_train - train_label_raw, 2, axis=0) / (np.linalg.norm(train_label_raw-train_label_raw.mean(axis=0), 2, axis=0) + 1e-5)\n",
    "se_test = np.linalg.norm(prediction_test - test_label_raw, 2, axis=0) / (np.linalg.norm(test_label_raw-test_label_raw.mean(axis=0), 2, axis=0) + 1e-5)\n",
    "rse_train = np.median(se_train, axis=0)\n",
    "rse_test = np.median(se_test, axis=0)\n",
    "print('Relative SE after de-normalization: train {:.3e}, test {:.3e}'.format(rse_train.mean(), rse_test.mean()))\n",
    "\n",
    "### Evaluation\n",
    "rse = evaluation(test_data_torch, test_label_raw)\n",
    "print(np.median(rse,axis=0))\n",
    "print('Overall:', np.median(rse,axis=0).mean())\n",
    "    \n",
    "if use_wandb:\n",
    "    wandb.log({\"Training Time\": (time.time()-start_time)/60})\n",
    "    wandb.log({\"Train Relative SE\": rse_train.mean()})\n",
    "    wandb.log({\"Test Relative SE\": rse_test.mean()})\n",
    "    wandb.log({\"Detailed Relative SE\": rse_train})\n",
    "    wandb.log({\"Detailed Relative SE\": rse_test})\n",
    "    \n",
    "    wandb.log({\"Prediction RSE\": np.median(rse,axis=0)})\n",
    "    wandb.log({\"Overall\": np.median(rse,axis=0).mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'GRU_CL0.75.pt')\n",
    "\n",
    "# Save model to wandb\n",
    "if use_wandb:\n",
    "    import os\n",
    "    torch.save({'model_state_dict':model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'epoch': i, 'loss_curve':loss_curve}, os.path.join(wandb.run.dir, 'model.pt'))\n",
    "#     torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'orange', 'b', 'b', 'b']\n",
    "c2 = ['C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'darkorange', 'C0', 'C0', 'C0']\n",
    "x = np.arange(7)\n",
    "# xticks=('0\\nR:bus_v', '1\\nI:bus_v', '2\\nR:cur1', '3\\nR:cur2', '4\\nR:cur3', '5\\nR:cur4', '6\\nR:cur5', '7\\nI:cur1', '8\\nI:cur2', '9\\nI:cur3', \\\n",
    "#                        '10\\nI:cur4', '11\\nI:cur5', '12\\nbus_freq', '13\\nmac_ang', '14\\nmac_spd', '15\\npelect', '16\\npmech', '17\\nqelect')\n",
    "xticks = ('0\\nR:bus_v', '1\\nI:bus_v', '2\\nmac_ang', '3\\nmac_spd', '4\\npelect', '5\\npmech', '6\\nqelect')\n",
    "width = 0.35\n",
    "\n",
    "# plt.figure(1,figsize=(15,7))\n",
    "# plt.bar(range(8), data_std, color=c)\n",
    "# plt.xticks(range(8), ('0\\nR:bus_v', '1\\nI:bus_v', '2\\nR:cur1', '3\\nR:cur2', '4\\nR:cur3', '5\\nR:cur4', '6\\nR:cur5', '7\\nI:cur1', '8\\nI:cur2', '9\\nI:cur3', \\\n",
    "#                        '10\\nI:cur4', '11\\nI:cur5', '12\\nbus_freq', '13\\nmac_ang', '14\\nmac_spd', '15\\npelect', '16\\npmech', '17\\nqelect'))\n",
    "# plt.grid(True)\n",
    "# plt.xlim([-0.5,17.5])\n",
    "# # plt.ylim([0,0.001])\n",
    "# plt.title('Standard Deviations on different components')\n",
    "\n",
    "mse_train_n = np.mean(np.mean(np.square(prediction_train_raw - train_label), axis=1), axis=0)\n",
    "mse_test_n = np.mean(np.mean(np.square(prediction_test_raw - test_label), axis=1), axis=0)\n",
    "\n",
    "plt.figure(2, figsize=(15, 7))\n",
    "plt.bar(x-width/2, mse_train_n, width, label='Train', color=c)\n",
    "plt.bar(x+width/2, mse_test_n, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 7.5])\n",
    "plt.legend()\n",
    "# plt.ylim([0,1e-6])\n",
    "plt.title('MSE on different components, normalized')\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(15, 7))\n",
    "plt.bar(x-width/2, rse_train, width, label='Train', color=c)\n",
    "plt.bar(x+width/2, rse_test, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 7.5])\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "# plt.ylim([0,1e-1])\n",
    "plt.title('Relative SE on different components')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_mode = 0 # 0:no cheating  1: replace accord to the list  2: replace all others  3: replace all, including the plotting one\n",
    "# entry = np.floor(np.random.uniform(low=0, high=1600, size=(1, 1))).astype(int).reshape(-1)\n",
    "entry = np.floor(np.random.uniform(low=4800, high=5200, size=(1, 1))).astype(int).reshape(-1)\n",
    "\n",
    "entry=[5085]\n",
    "# entry =[2108]  % contigency at Line 5\n",
    "# entry=[4880]  % another contigency at Line 5\n",
    "entry = sample_idx[entry]\n",
    "t_max = 700\n",
    "if use_cur_sum:\n",
    "    quantities = [0,1,4,5,6,7,8]  # in data indices\n",
    "    quantities_transform = [0, 1, -1, -1, 2, 3, 4, 5, 6]  # transform data indices to label indices\n",
    "    quantites_names = ['Mag:bus_v', 'Ang:bus_v', 'M:cur_sum', 'A:cur_sum', 'mac_ang', 'mac_spd', 'pelect', 'pmech', 'qelect']\n",
    "    quantities_replace = [0,1]  # replace these in data indices\n",
    "#     quantities_replace = [0,1,4,5,6,7,8,9]  # replace these in data indices\n",
    "else:\n",
    "    quantities = [0,1,12,13,14,15,16,17]\n",
    "    quantities_transform = [0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 3, 4, 5, 6, 7]\n",
    "    quantites_names = ['Mag:bus_v', 'Ang:bus_v', 'M:cur1', 'M:cur2', 'M:cur3', 'M:cur4', 'M:cur5', 'A:cur1', 'A:cur2', 'A:cur3', 'A:cur4', 'A:cur5', 'mac_ang', 'mac_spd', 'pelect', 'pmech', 'qelect']\n",
    "    quantities_replace = [0,1,12,13,15,16,17]\n",
    "    \n",
    "if replace_mode == 0:\n",
    "    print('No Cheating.')\n",
    "elif replace_mode == 1:\n",
    "    print('Replacing quantites:')\n",
    "    for q in quantities_replace:\n",
    "        print('    [{:d}]'.format(q),quantites_names[q])\n",
    "    print('Keeping quantites:')\n",
    "    for q in quantities:\n",
    "        if not (q in quantities_replace):\n",
    "            print('    [{:d}]'.format(q),quantites_names[q])\n",
    "    print()\n",
    "elif replace_mode == 2:\n",
    "       print('Replacing all other quantities except the plotting one.')\n",
    "elif replace_mode == 3:\n",
    "       print('Replacing all quantities.')\n",
    "\n",
    "model.eval()\n",
    "for i in entry:    \n",
    "    bus_v = data['bus_v'][0][i].reshape(-1, 1)\n",
    "    cur = data['cur'][0][i].reshape(-1, 1)\n",
    "#     bus_freq = data['bus_freq'][0][i].reshape(-1, 1)\n",
    "    mac_ang = data['mac_ang'][0][i].reshape(-1, 1)\n",
    "    mac_spd = data['mac_spd'][0][i].reshape(-1, 1)\n",
    "    pelect = data['pelect'][0][i].reshape(-1, 1)\n",
    "    pmech = data['pmech'][0][i].reshape(-1, 1)\n",
    "    qelect = data['qelect'][0][i].reshape(-1, 1)\n",
    "\n",
    "    if use_mac_ang_filter and mac_ang[-1]>1000:\n",
    "        print('Not valid:', data['filename'][0][i], mac_ang[-1])\n",
    "        continue\n",
    "\n",
    "#     if use_cur_sum:\n",
    "#         cur = np.sum(cur, axis=1).reshape(-1, 1)\n",
    "        \n",
    "    bus_v_ang = np.unwrap(np.angle(bus_v).reshape(-1)).reshape(-1,1)\n",
    "    cur_ang = np.unwrap(np.angle(cur).reshape(-1)).reshape(-1,1)\n",
    "    tmp_test_data = np.hstack([np.abs(bus_v), bus_v_ang, np.abs(cur), cur_ang, mac_ang, mac_spd, pelect, pmech, qelect])\n",
    "#     tmp_test_data = np.array(tmp_test_data, dtype=np.float32)\n",
    "    \n",
    "    tmp_test_label = np.delete(tmp_test_data, 0, 0)  # delete the first sample(shift the curve left)\n",
    "    if use_cur_sum:\n",
    "        tmp_test_label = np.delete(tmp_test_label, np.arange(2, 4), 1)\n",
    "    else:\n",
    "        tmp_test_label = np.delete(tmp_test_label, np.arange(2, 12), 1)\n",
    "    tmp_test_data = np.delete(tmp_test_data, -1, 0)\n",
    "    \n",
    "    \n",
    "    tmp_test_data = (tmp_test_data - data_mean) / data_std\n",
    "    tmp_test_data = torch.from_numpy(tmp_test_data).to(device).float()\n",
    "\n",
    "    for q in range(9):\n",
    "        if quantites_names[q] == 'pmech':\n",
    "            continue\n",
    "        if not (q in quantities):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            if q==2:\n",
    "                plt.plot(range(t_max-1), np.abs(cur)[1:t_max], 'r')\n",
    "            if q==3:\n",
    "                plt.plot(range(t_max-1), cur_ang[1:t_max], 'r')\n",
    "            plt.grid(True)\n",
    "            plt.title('#{:d}: [{:s}]'.format(i, quantites_names[q]))\n",
    "            continue\n",
    "#         if q in quantities_replace:\n",
    "#             continue\n",
    "        rnn_states = model.initial_states()\n",
    "        output_data = np.zeros_like(tmp_test_label)\n",
    "        input_data_torch = tmp_test_data[0, :].reshape(1,1,-1)\n",
    "        \n",
    "        for t in range(0, t_max):\n",
    "            output_data_torch, rnn_states = model(input_data_torch, rnn_states)\n",
    "            output_data[t,:] = output_data_torch.data.cpu().numpy()\n",
    "            \n",
    "            input_data_torch = torch.cat((output_data_torch[0,0,0:2], tmp_test_data[t+1,2:4], output_data_torch[0,0,2:])).reshape(1,1,-1)\n",
    "\n",
    "            for r in quantities:\n",
    "                if ((replace_mode == 1) and (r in quantities_replace)) or ((replace_mode == 2) and (r != q)) or (replace_mode == 3):\n",
    "                    input_data_torch[0,0,r] = tmp_test_data[t+1, r]\n",
    "\n",
    "        output_data = output_data * label_std + label_mean\n",
    "\n",
    "        truth_curve = tmp_test_label[:t_max, quantities_transform[q]]\n",
    "        pred_curve = output_data[:t_max, quantities_transform[q]]\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(range(t_max), truth_curve, 'r', label='Truth')\n",
    "        plt.plot(range(t_max), pred_curve, 'b', label='Pred')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        rmse = np.sqrt(np.mean(np.square(truth_curve - pred_curve)))\n",
    "        rse = np.linalg.norm(truth_curve - pred_curve, 2)/ np.linalg.norm(truth_curve-truth_curve.mean(), 2)\n",
    "        plt.title('#{:d}: [{:s}] Pred RMSE={:.4e}, Relative SE = {:.4e}'.format(i, quantites_names[q], rmse, rse))\n",
    "        \n",
    "# plt.show()\n",
    "\n",
    "# sio.savemat('example1.mat',{'label':tmp_test_label, 'data':output_data})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# def plot_grad_flow(named_parameters):\n",
    "#     ave_grads = []\n",
    "#     layers = []\n",
    "#     for n, p in named_parameters:\n",
    "#         if(p.requires_grad) and (\"bias\" not in n):\n",
    "#             layers.append(n)\n",
    "#             ave_grads.append(p.grad.abs().mean())\n",
    "#     plt.figure()\n",
    "#     plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "#     plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "#     plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "#     plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "#     plt.xlabel(\"Layers\")\n",
    "#     plt.ylabel(\"average gradient\")\n",
    "#     plt.title(\"Gradient flow\")\n",
    "#     plt.grid(True)\n",
    "\n",
    "# debug\n",
    "#         print(loss.item())\n",
    "#         plt.figure()\n",
    "#         plt.hist(loss_r, bins=50)\n",
    "#         plt.title('epoch '+str(i)+'batch '+str(j))\n",
    "#         if loss_r.max()>0.1:\n",
    "#             plt.xlim((0,loss_r.max()))\n",
    "#         else:\n",
    "#             plt.xlim((0,0.1))\n",
    "#         plot_grad_flow(model.named_parameters())\n",
    "#         plt.figure()\n",
    "#         plt.hist(model.lstm.weight_ih_l0.grad.cpu().data.numpy().reshape(-1), color='r', bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
