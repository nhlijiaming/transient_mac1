{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "use_wandb = False\n",
    "if use_wandb:\n",
    "    import wandb\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = 'mac1_tuning.ipynb'\n",
    "    wandb.init(project=\"transient_mac1\", notes=\"\")\n",
    "    wandb.run.name = '192_192_dedicated_128_128_VaMacang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mac1 import Machine1\n",
    "print(time.strftime('%H:%M:%S  ', time.localtime(time.time())))\n",
    "\n",
    "mac1 = Machine1(n_layers=2, hidden_dim=[192,192], n_training_sample=1600, data_len=700, batchsize=200, data_interpolation_rate=5)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {mac1.model.n_layers} layers and totaling {count_parameters(mac1.model):,} trainable parameters.')\n",
    "\n",
    "# load_file = '6_22_2020.pt'\n",
    "# load_file = 'saved_models/txfxwfte/400.pt'\n",
    "# load_file = 'wandb/run-20200730_131951-1wkdkg8l/checkpoint/970.pt' # 400_192+128_dedicated_VaMacang\n",
    "# load_file = 'wandb/run-20200730_180343-2f174fnm/checkpoint/990.pt' # 400_192+128_dedicated_VaMacang_weightedLoss*10\n",
    "# load_file = 'wandb/run-20200730_161725-uo241gfh/checkpoint/940.pt' # 400_192+128_dedicated_VaMacang_trainable-initmem\n",
    "# load_file = 'wandb/run-20200730_125334-27vk5mbn/checkpoint/860.pt' # 400_192+128_dedicated+shared_VaMacang_trainable-initmem\n",
    "\n",
    "\n",
    "# load_file = 'wandb/60.pt'\n",
    "# load_file = '../replicate/LSTM_repl_1600_860Epochs.pt'\n",
    "\n",
    "if 'load_file' in locals():\n",
    "    mac1.load_pretrained(load_file)\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.config.teacher_forcing = mac1.teacher_forcing_ratio\n",
    "    wandb.config.teacher_forcing_ratio_decay = mac1.teacher_forcing_ratio_decay\n",
    "\n",
    "    wandb.config.architecture = 'LSTM'#mac1.architecture\n",
    "    wandb.config.n_layers = 2#mac1.n_layers\n",
    "    wandb.config.hidden_dim = '128->128(Va, mac_ang);192->192(others)'#mac1.hidden_dim\n",
    "\n",
    "    wandb.config.training_sample = mac1.n_training_sample\n",
    "    wandb.config.data_len = mac1.data_len\n",
    "    wandb.config.apply_mac_ang_filter = True#mac1.apply_mac_ang_filter\n",
    "    wandb.config.angle_setting = 'Polar, unwarped'\n",
    "\n",
    "    loss, _ = mac1.test(mac1.train_data_torch, mac1.train_label_torch)\n",
    "    loss_test, _ = mac1.test(mac1.test_data_torch, mac1.test_label_torch)\n",
    "    rse = mac1.evaluation(mac1.test_data_torch, mac1.test_label_raw)\n",
    "    wandb.log({\"Epoch\": mac1.trained_epochs-1, \"Train Loss\": loss, \"Test Loss\": loss_test, 'Eval RSE':np.median(rse,axis=0).mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### %matplotlib inline\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "trained_epochs = mac1.trained_epochs\n",
    "train_for_epochs = 1000 if use_wandb else 0\n",
    "min_eval_rse = np.inf\n",
    "save_to_file = False\n",
    "for i in range(trained_epochs, trained_epochs+train_for_epochs):\n",
    "    mac1.train_for_one_epoch()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        loss, _ = mac1.test(mac1.train_data_torch, mac1.train_label_torch)\n",
    "        loss_test, _ = mac1.test(mac1.test_data_torch, mac1.test_label_torch)\n",
    "        mac1.loss_curve.append([i, loss, loss_test])\n",
    "        \n",
    "        rse_train = mac1.evaluation(mac1.train_data_torch, mac1.train_label_raw)\n",
    "        rse_test = mac1.evaluation(mac1.test_data_torch, mac1.test_label_raw)\n",
    "        \n",
    "        if use_wandb:\n",
    "            if np.median(rse_test,axis=0).mean() < min_eval_rse:\n",
    "                min_eval_rse = np.median(rse_test,axis=0).mean()\n",
    "                save_to_file = True\n",
    "            \n",
    "            wandb.log({\"Epoch\": i, \"Train Loss\": loss, \"Test Loss\": loss_test, 'Eval RSE in training':np.median(rse_train,axis=0).mean(), 'Eval RSE':np.median(rse_test,axis=0).mean()})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        ETA = (time.time() - start_time) / (i - trained_epochs + 1) * (trained_epochs+train_for_epochs-i) / 60\n",
    "        print(time.strftime('%H:%M:%S  ', time.localtime(time.time())), end=\"\")\n",
    "        print('ETA:{:.1f}mins '.format(ETA), end=\"\")\n",
    "        print('Epoch {}: train Loss = {:.3e}, test Loss = {:.3e}, eval = {:.3e}'.format(i, loss, loss_test, np.median(rse_test,axis=0).mean()))\n",
    "\n",
    "    if use_wandb and i % 100 == 0:\n",
    "        save_to_file = True\n",
    "        \n",
    "    if save_to_file:\n",
    "        save_to_file = False\n",
    "        \n",
    "        if not os.path.exists(os.path.join(wandb.run.dir, 'checkpoint')):\n",
    "            os.makedirs(os.path.join(wandb.run.dir, 'checkpoint'))\n",
    "\n",
    "        torch.save({'model_state_dict': mac1.model.state_dict(), \n",
    "                    'optimizer_state_dict': mac1.optimizer.state_dict(), \n",
    "                    'epoch': i,\n",
    "                    'loss_curve':mac1.loss_curve\n",
    "                    },\n",
    "                   '{:s}/{:d}.pt'.format(os.path.join(wandb.run.dir, 'checkpoint'), i))\n",
    "        \n",
    "print('Training process took {:.1f} mins.'.format((time.time()-start_time)/60))\n",
    "\n",
    "if len(mac1.loss_curve) > 0:\n",
    "    plt.figure(0, figsize=(15, 5))\n",
    "    plt.plot(np.array(mac1.loss_curve)[:, 0], np.array(mac1.loss_curve)[:, 1], 'r', label=\"Train\")\n",
    "    plt.plot(np.array(mac1.loss_curve)[:, 0], np.array(mac1.loss_curve)[:, 2], 'b', label=\"Test\")\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "if mac1.use_GPU:\n",
    "    print('GPU memory stats: Max Cached {:.0f} Mb, Max Reserved {:.0f} Mb, Max Allocated {:.0f} Mb'.format(\n",
    "        torch.cuda.max_memory_cached(0)/1024/1024, torch.cuda.max_memory_reserved(0)/1024/1024, torch.cuda.max_memory_allocated(0)/1024/1024))\n",
    "\n",
    "_, prediction_train_raw = mac1.test(mac1.train_data_torch, mac1.train_label_torch)\n",
    "_, prediction_test_raw = mac1.test(mac1.test_data_torch, mac1.test_label_torch)\n",
    "\n",
    "prediction_train = prediction_train_raw * mac1.label_std + mac1.label_mean\n",
    "prediction_test = prediction_test_raw * mac1.label_std + mac1.label_mean\n",
    "    \n",
    "mse_train = np.mean(np.mean(np.square(prediction_train - mac1.train_label_raw), axis=1), axis=0)\n",
    "mse_test = np.mean(np.mean(np.square(prediction_test - mac1.test_label_raw), axis=1), axis=0)\n",
    "\n",
    "print('Denormalized: train Loss = %.3e, test Loss = %.3e' % (mse_train.mean(), mse_test.mean()))\n",
    "\n",
    "se_train = np.linalg.norm(prediction_train - mac1.train_label_raw, 2, axis=0) / (np.linalg.norm(mac1.train_label_raw-mac1.train_label_raw.mean(axis=0), 2, axis=0) + 1e-5)\n",
    "se_test = np.linalg.norm(prediction_test - mac1.test_label_raw, 2, axis=0) / (np.linalg.norm(mac1.test_label_raw-mac1.test_label_raw.mean(axis=0), 2, axis=0) + 1e-5)\n",
    "rse_train = np.median(se_train, axis=0)\n",
    "rse_test = np.median(se_test, axis=0)\n",
    "print('Relative SE after de-normalization: train {:.3e}, test {:.3e}'.format(rse_train.mean(), rse_test.mean()))\n",
    "\n",
    "### Evaluation\n",
    "rse = mac1.evaluation(mac1.test_data_torch, mac1.test_label_raw)\n",
    "print()\n",
    "print('Detailed RRMSE:', np.median(rse,axis=0))\n",
    "print('Average of RRMSE:', np.median(rse,axis=0).mean())\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.log({\"Training Time\": (time.time()-start_time)/60})\n",
    "    wandb.log({\"Train Relative SE\": rse_train.mean()})\n",
    "    wandb.log({\"Test Relative SE\": rse_test.mean()})\n",
    "    wandb.log({\"Detailed Relative SE\": rse_train})\n",
    "    wandb.log({\"Detailed Relative SE\": rse_test})\n",
    "    \n",
    "    wandb.log({\"Prediction RSE\": np.median(rse,axis=0)})\n",
    "    wandb.log({\"Overall\": np.median(rse,axis=0).mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model_state_dict':mac1.model.state_dict(), 'optimizer_state_dict': mac1.optimizer.state_dict(), 'epoch': mac1.trained_epochs, 'loss_curve':mac1.loss_curve}, '6_23_2020.pt')\n",
    "\n",
    "# Save model to wandb\n",
    "if use_wandb:\n",
    "    torch.save({'model_state_dict':mac1.model.state_dict(), \n",
    "                'optimizer_state_dict': mac1.optimizer.state_dict(), \n",
    "                'epoch': mac1.trained_epochs, \n",
    "                'loss_curve':mac1.loss_curve\n",
    "               }, \n",
    "               os.path.join(wandb.run.dir, 'model.pt'))\n",
    "#     torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'orange', 'b', 'b', 'b']\n",
    "c2 = ['C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'C0', 'darkorange', 'C0', 'C0', 'C0']\n",
    "x = np.arange(7)\n",
    "# xticks=('0\\nR:bus_v', '1\\nI:bus_v', '2\\nR:cur1', '3\\nR:cur2', '4\\nR:cur3', '5\\nR:cur4', '6\\nR:cur5', '7\\nI:cur1', '8\\nI:cur2', '9\\nI:cur3', \\\n",
    "#                        '10\\nI:cur4', '11\\nI:cur5', '12\\nbus_freq', '13\\nmac_ang', '14\\nmac_spd', '15\\npelect', '16\\npmech', '17\\nqelect')\n",
    "xticks = ('0\\nMag:bus_v', '1\\nAngle:bus_v', '2\\nmac_ang', '3\\nmac_spd', '4\\npelect', '5\\npmech', '6\\nqelect')\n",
    "width = 0.35\n",
    "\n",
    "# plt.figure(1,figsize=(15,7))\n",
    "# plt.bar(range(8), data_std, color=c)\n",
    "# plt.xticks(range(8), ('0\\nR:bus_v', '1\\nI:bus_v', '2\\nR:cur1', '3\\nR:cur2', '4\\nR:cur3', '5\\nR:cur4', '6\\nR:cur5', '7\\nI:cur1', '8\\nI:cur2', '9\\nI:cur3', \\\n",
    "#                        '10\\nI:cur4', '11\\nI:cur5', '12\\nbus_freq', '13\\nmac_ang', '14\\nmac_spd', '15\\npelect', '16\\npmech', '17\\nqelect'))\n",
    "# plt.grid(True)\n",
    "# plt.xlim([-0.5,17.5])\n",
    "# # plt.ylim([0,0.001])\n",
    "# plt.title('Standard Deviations on different components')\n",
    "\n",
    "mse_train_n = np.mean(np.mean(np.square(prediction_train_raw - mac1.train_label_raw), axis=1), axis=0)\n",
    "mse_test_n = np.mean(np.mean(np.square(prediction_test_raw - mac1.test_label_raw), axis=1), axis=0)\n",
    "\n",
    "plt.figure(2, figsize=(12, 5))\n",
    "plt.bar(x-width/2, mse_train_n, width, label='Train', color=c)\n",
    "plt.bar(x+width/2, mse_test_n, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 6.5])\n",
    "plt.legend()\n",
    "# plt.ylim([0,1e-6])\n",
    "plt.title('MSE on different components, normalized')\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(12, 5))\n",
    "plt.bar(x-width/2, rse_train, width, label='Train', color=c)\n",
    "plt.bar(x+width/2, rse_test, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 6.5])\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "# plt.ylim([0,1e-1])\n",
    "plt.title('Relative SE on different components')\n",
    "\n",
    "\n",
    "eval_rse_train = mac1.evaluation(mac1.train_data_torch, mac1.train_label_raw)\n",
    "eval_rse_test = mac1.evaluation(mac1.test_data_torch, mac1.test_label_raw)\n",
    "eval_rse_train = np.median(eval_rse_train,axis=0)\n",
    "eval_rse_test = np.median(eval_rse_test,axis=0)\n",
    "plt.figure(4, figsize=(12, 5))\n",
    "plt.bar(x-width/2, eval_rse_train, width, label='Train', color=c)\n",
    "plt.bar(x+width/2, eval_rse_test, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 6.5])\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "# plt.ylim([0,1e-1])\n",
    "plt.title('RRMSE on different components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# entry = np.floor(np.random.uniform(low=0, high=1600, size=(1, 1))).astype(int).reshape(-1)\n",
    "# entry = np.floor(np.random.uniform(low=4800, high=5200, size=(1, 1))).astype(int).reshape(-1)\n",
    "\n",
    "entry=[3678]\n",
    "# entry =[2108]  % contigency at Line 5\n",
    "# entry=[4880]  % another contigency at Line 5\n",
    "# entry = [4800]\n",
    "# entry = mac1.sample_idx[entry]\n",
    "t_max = 900\n",
    "\n",
    "quantities = [0,1,4,5,6,7,8]  # in data indices\n",
    "quantities_transform = [0, 1, -1, -1, 2, 3, 4, 5, 6]  # transform data indices to label indices\n",
    "quantites_names = ['Mag:bus_v', 'Ang:bus_v', 'M:cur_sum', 'A:cur_sum', 'mac_ang', 'mac_spd', 'pelect', 'pmech', 'qelect']\n",
    "\n",
    "mac1.model.eval()\n",
    "for i in entry:    \n",
    "    filename = mac1.data['filename'][0][i][0]\n",
    "    if (filename.find('a5a') > -1 or filename.find('a5.') > -1):\n",
    "        print('WARRNING: {:s} contains a line-5 fault.'.format(data['filename'][0][i][0]))\n",
    "\n",
    "    tmp_test_data, tmp_test_label = mac1.extract_data(i, t_max, data_interpolation_rate=5)\n",
    "    \n",
    "    tmp_test_data = (tmp_test_data - mac1.data_mean) / mac1.data_std\n",
    "    tmp_test_data = torch.from_numpy(tmp_test_data).to(mac1.device).float()\n",
    "\n",
    "    output_data = np.zeros_like(tmp_test_label)\n",
    "    t_start = 0\n",
    "    rnn_states = mac1.model.initial_states()\n",
    "    input_data_torch = tmp_test_data[t_start, :].reshape(1,1,-1)\n",
    "    for t in range(t_start, t_max):\n",
    "        output_data_torch, rnn_states = mac1.model(input_data_torch, rnn_states)\n",
    "        output_data[t,:] = output_data_torch.data.cpu().numpy()\n",
    "        if t < t_max-1:\n",
    "            input_data_torch = torch.cat((output_data_torch[0,0,0:2],\n",
    "                                          tmp_test_data[t+1,2:4], \n",
    "                                          output_data_torch[0,0,2:7], \n",
    "                                          tmp_test_data[t+1,9:11])\n",
    "                                        ).reshape(1,1,-1)\n",
    "\n",
    "    output_data = output_data * mac1.label_std + mac1.label_mean\n",
    "\n",
    "    for q in range(9):\n",
    "        if quantites_names[q] == 'pmech':\n",
    "            continue\n",
    "        if not (q in quantities):\n",
    "#             plt.figure(q, figsize=(12, 8))\n",
    "#             if q==2:\n",
    "#                 plt.plot(range(t_max-1), tmp_test_data[1:t_max,2], 'r')\n",
    "#             if q==3:\n",
    "#                 plt.plot(range(t_max-1), tmp_test_data[1:t_max,3], 'r')\n",
    "#             plt.grid(True)\n",
    "#             plt.title('#{:d}: [{:s}]'.format(i, quantites_names[q]))\n",
    "            continue\n",
    "        plt.figure(q, figsize=(12, 8))\n",
    "        truth_curve = tmp_test_label[:t_max, quantities_transform[q]]\n",
    "        pred_curve = output_data[:t_max, quantities_transform[q]]\n",
    "\n",
    "        plt.plot(range(t_max), truth_curve, 'r', label='Truth')\n",
    "        plt.plot(range(t_max), pred_curve, 'b', label='Pred')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        rmse = np.sqrt(np.mean(np.square(truth_curve - pred_curve)))\n",
    "        rse = np.linalg.norm(truth_curve - pred_curve, 2)/ (np.linalg.norm(truth_curve-truth_curve.mean(), 2) + 1e-6)\n",
    "        plt.title('#{:d}: [{:s}] Pred RMSE={:.4e}, Relative SE = {:.4e}'.format(i, quantites_names[q], rmse, rse))\n",
    "#         plt.xlim([0,50])\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# sio.savemat('example1.mat',{'label':tmp_test_label, 'data':output_data})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "replace_mode = 0 # 0:no cheating  1: replace accord to the list  2: replace all others  3: replace all, including the plotting one\n",
    "# entry = np.floor(np.random.uniform(low=0, high=1600, size=(1, 1))).astype(int).reshape(-1)\n",
    "# entry = np.floor(np.random.uniform(low=4800, high=5200, size=(1, 1))).astype(int).reshape(-1)\n",
    "\n",
    "entry=[5142]\n",
    "# entry =[2108]  % contigency at Line 5\n",
    "# entry=[4880]  % another contigency at Line 5\n",
    "# entry = [4800]\n",
    "# entry = mac1.sample_idx[entry]\n",
    "t_max = 995\n",
    "quantities = [0,1,4,5,6,7,8]  # in data indices\n",
    "quantities_transform = [0, 1, -1, -1, 2, 3, 4, 5, 6]  # transform data indices to label indices\n",
    "quantites_names = ['Mag:bus_v', 'Ang:bus_v', 'M:cur_sum', 'A:cur_sum', 'mac_ang', 'mac_spd', 'pelect', 'pmech', 'qelect']\n",
    "quantities_replace = [0,1]  # replace these in data indices\n",
    "#     quantities_replace = [0,1,4,5,6,7,8,9]  # replace these in data indices\n",
    "\n",
    "if replace_mode == 0:\n",
    "    print('No Cheating.')\n",
    "elif replace_mode == 1:\n",
    "    print('Replacing quantites:')\n",
    "    for q in quantities_replace:\n",
    "        print('    [{:d}]'.format(q),quantites_names[q])\n",
    "    print('Keeping quantites:')\n",
    "    for q in quantities:\n",
    "        if not (q in quantities_replace):\n",
    "            print('    [{:d}]'.format(q),quantites_names[q])\n",
    "    print()\n",
    "elif replace_mode == 2:\n",
    "       print('Replacing all other quantities except the plotting one.')\n",
    "elif replace_mode == 3:\n",
    "       print('Replacing all quantities.')\n",
    "\n",
    "mac1.model.eval()\n",
    "for i in entry:    \n",
    "    filename = mac1.data['filename'][0][i][0]\n",
    "    if (filename.find('a5a') > -1 or filename.find('a5.') > -1):\n",
    "        print('WARRNING: {:s} contains a line-5 fault.'.format(data['filename'][0][i][0]))\n",
    "\n",
    "    tmp_test_data, tmp_test_label = mac1.extract_data(i, t_max)\n",
    "    \n",
    "    tmp_test_data = (tmp_test_data - mac1.data_mean) / mac1.data_std\n",
    "    tmp_test_data = torch.from_numpy(tmp_test_data).to(mac1.device).float()\n",
    "\n",
    "    for q in range(9):\n",
    "        if quantites_names[q] == 'pmech':\n",
    "            continue\n",
    "        if not (q in quantities):\n",
    "#             plt.figure(q, figsize=(12, 8))\n",
    "#             if q==2:\n",
    "#                 plt.plot(range(t_max-1), tmp_test_data[1:t_max,2], 'r')\n",
    "#             if q==3:\n",
    "#                 plt.plot(range(t_max-1), tmp_test_data[1:t_max,3], 'r')\n",
    "#             plt.grid(True)\n",
    "#             plt.title('#{:d}: [{:s}]'.format(i, quantites_names[q]))\n",
    "            continue\n",
    "#         if q in quantities_replace:\n",
    "#             continue\n",
    "        output_data = np.zeros_like(tmp_test_label)\n",
    "\n",
    "\n",
    "        for t_start in [0]:\n",
    "            rnn_states = mac1.model.initial_states()\n",
    "            input_data_torch = tmp_test_data[t_start, :].reshape(1,1,-1)\n",
    "            for t in range(t_start, t_max):\n",
    "                output_data_torch, rnn_states = mac1.model(input_data_torch, rnn_states)\n",
    "                output_data[t,:] = output_data_torch.data.cpu().numpy()\n",
    "                if t < t_max-1:\n",
    "                    input_data_torch = torch.cat((output_data_torch[0,0,0:2],\n",
    "                                                  tmp_test_data[t+1,2:4], \n",
    "                                                  output_data_torch[0,0,2:7], \n",
    "                                                  tmp_test_data[t+1,9:11])\n",
    "                                                ).reshape(1,1,-1)\n",
    "\n",
    "#                 for r in quantities:\n",
    "#                     if ((replace_mode == 1) and (r in quantities_replace)) or ((replace_mode == 2) and (r != q)) or (replace_mode == 3):\n",
    "#                         input_data_torch[0,0,r] = tmp_test_data[t+1, r]\n",
    "\n",
    "            output_data = output_data * mac1.label_std + mac1.label_mean\n",
    "        \n",
    "            truth_curve = tmp_test_label[:t_max, quantities_transform[q]]\n",
    "            pred_curve = output_data[:t_max, quantities_transform[q]]\n",
    "            \n",
    "            plt.figure(q, figsize=(12, 8))\n",
    "            \n",
    "            if t_start == 0:\n",
    "                plt.plot(range(t_max), truth_curve, 'r', label='Truth')\n",
    "                plt.plot(range(t_max), pred_curve, 'b', label='Pred')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                rmse = np.sqrt(np.mean(np.square(truth_curve - pred_curve)))\n",
    "                rse = np.linalg.norm(truth_curve - pred_curve, 2)/ (np.linalg.norm(truth_curve-truth_curve.mean(), 2) + 1e-6)\n",
    "                plt.title('#{:d}: [{:s}] Pred RMSE={:.4e}, Relative SE = {:.4e}'.format(i, quantites_names[q], rmse, rse))\n",
    "            else:\n",
    "                plt.plot(range(t_start, t_max), pred_curve[t_start:])\n",
    "        \n",
    "# plt.show()\n",
    "\n",
    "# sio.savemat('example1.mat',{'label':tmp_test_label, 'data':output_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac1.model.init_cell_state_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_rse_train = mac1.evaluation(mac1.train_data_torch, mac1.train_label_raw)\n",
    "def ev(mac, eval_data_torch, eval_label_raw, eval_batchsize = 200):\n",
    "    model, device = mac.model, mac.device\n",
    "    t_max = 10\n",
    "    samples = eval_data_torch.shape[1]\n",
    "    rse = np.zeros((samples,7))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,samples,eval_batchsize):\n",
    "            rnn_states = model.initial_states()\n",
    "            output_data = np.zeros((t_max, eval_batchsize, 7))\n",
    "            input_data_torch = eval_data_torch[0, i:i+eval_batchsize, :].reshape(1,eval_batchsize,-1).to(device)\n",
    "\n",
    "            for t in range(0, t_max):\n",
    "                output_data_torch, rnn_states = model(input_data_torch, rnn_states)\n",
    "                output_data[t,:] = output_data_torch.data.cpu().numpy()\n",
    "\n",
    "                # construct mini-batch data\n",
    "                if t<t_max-1:\n",
    "                    input_data_torch = torch.cat((output_data_torch[0,:,0:2],\n",
    "                                              eval_data_torch[t+1,i:i+eval_batchsize,2:4].to(device), \n",
    "                                              output_data_torch[0,:,2:7], \n",
    "                                              eval_data_torch[t+1,i:i+eval_batchsize,9:11].to(device)\n",
    "                                             ), dim=1).reshape(1,eval_batchsize,-1)\n",
    "\n",
    "            # de-normalize before computing Relative RMSE\n",
    "            output_data = output_data * mac.label_std + mac.label_mean\n",
    "\n",
    "            for b in range(eval_batchsize):\n",
    "                for q in range(7):\n",
    "\n",
    "                    # skip pmech, which is a constant\n",
    "                    if q == 5:\n",
    "                        continue\n",
    "\n",
    "                    truth_curve = eval_label_raw[:t_max, i+b, q]\n",
    "                    pred_curve = output_data[:t_max, b, q]\n",
    "                    rse[i+b,q] = np.linalg.norm(truth_curve - pred_curve, 2) / (np.linalg.norm(truth_curve-truth_curve.mean(), 2) + 1e-6)\n",
    "    return rse\n",
    "\n",
    "eval_rse_test = ev(mac1, mac1.test_data_torch, mac1.test_label_raw)\n",
    "eval_rse_test = np.median(eval_rse_test,axis=0)\n",
    "print(eval_rse_test)\n",
    "print(eval_rse_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_one_epoch(self):\n",
    "    model = self.model\n",
    "    optimizer = self.optimizer\n",
    "    device = self.device\n",
    "    criterion = self.criterion\n",
    "    data_len = self.data_len\n",
    "    batchsize = self.batchsize\n",
    "\n",
    "    train_data_torch = self.train_data_torch\n",
    "    train_label_torch = self.train_label_torch\n",
    "\n",
    "    model.eval()\n",
    "    if self.teacher_forcing_ratio_decay:\n",
    "        self.teacher_forcing_ratio *= 0.9975 #  0.9966\n",
    "\n",
    "    loss = 0\n",
    "    detailed_loss = np.zeros((data_len, self.n_training_sample, 7))\n",
    "    with torch.no_grad():\n",
    "        for j in range(0, self.n_training_sample, self.batchsize):\n",
    "            rnn_states = model.initial_states()\n",
    "\n",
    "            use_teacher_forcing = True\n",
    "            if use_teacher_forcing:\n",
    "                # with total teacher forcing, 20x faster\n",
    "                inputs = train_data_torch[:data_len, j:j+batchsize, :].reshape(data_len,batchsize,-1).to(device)\n",
    "                outputs, rnn_states = model(inputs, rnn_states)\n",
    "                labels = train_label_torch[:, j:j+batchsize, :].to(device)\n",
    "                loss += criterion(outputs, labels)\n",
    "                detailed_loss[:, j:j+200, :] = np.square(outputs.cpu().data.numpy() - labels.cpu().data.numpy())\n",
    "            else:\n",
    "                for t in range(data_len):\n",
    "                    # construct input data from previous output and external dataset\n",
    "                    inputs = train_data_torch[t, j:j+batchsize, :].reshape(1,batchsize,-1).clone().to(device)\n",
    "                    if t>0:\n",
    "                        # teacher forcing: replacing inputs with ground truth\n",
    "                        inputs[:,:,[0,1,4,5,6,7,8]] = outputs[0,:,[0,1,2,3,4,5,6]].detach()\n",
    "\n",
    "                    # forward\n",
    "                    outputs, rnn_states = model(inputs, rnn_states)\n",
    "\n",
    "                    # compute loss\n",
    "                    labels = train_label_torch[t, j:j+batchsize, :].reshape(1,batchsize,-1).to(device)\n",
    "                    loss += criterion(outputs, labels, weight=0.0)\n",
    "                    detailed_loss[t, j:j+200, :] = np.square(outputs.cpu().data.numpy() - labels.cpu().data.numpy())\n",
    "                loss /= data_len\n",
    "    loss /= (self.n_training_sample/self.batchsize)\n",
    "    print(loss.item())\n",
    "    return detailed_loss\n",
    "\n",
    "ret = train_for_one_epoch(mac1)\n",
    "print(ret.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_q = np.mean(np.mean(ret, axis=0),axis=0)\n",
    "\n",
    "plt.figure(4, figsize=(12, 5))\n",
    "plt.bar(x-width/2, mse_q, width, label='Train', color=c)\n",
    "# plt.bar(x+width/2, eval_rse_test, width, label='Test', color=c2)\n",
    "plt.xticks(x, xticks)\n",
    "plt.grid(True)\n",
    "plt.xlim([-0.5, 6.5])\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "# plt.ylim([0,1e-1])\n",
    "plt.title('MSE on different components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
